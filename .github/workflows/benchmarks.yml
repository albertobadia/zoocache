name: Benchmarks

on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main

jobs:
  benchmark:
    name: Performance Regression Check
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v5
        with:
          enable-cache: true

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install dependencies
        run: uv sync --dev

      - name: Capture Hardware Info
        run: |
          mkdir -p benchmarks/reports
          echo "- **CPU**: $(lscpu | grep 'Model name' | cut -f 2 -d ":" | awk '{$1=$1}1')" > benchmarks/reports/hardware.md
          echo "- **Cores**: $(nproc)" >> benchmarks/reports/hardware.md
          echo "- **Memory**: $(free -h | grep 'Mem' | awk '{print $2}')" >> benchmarks/reports/hardware.md
          echo "- **OS**: $(uname -smp)" >> benchmarks/reports/hardware.md

      - name: Run benchmarks
        run: |
          uv run pytest benchmarks/ --benchmark-only --benchmark-json=benchmarks/output.json

      - name: Generate performance fragment
        run: |
          uv run python benchmarks/reports/update_readme.py

      - name: Update README with markdown-autodocs
        uses: dineshsonachalam/markdown-autodocs@v1.0.4
        with:
          # Optional: Use a custom configuration file
          # config_file: .github/markdown-autodocs.yml
          commit_message: "docs: update benchmark results in README"

      - name: Store benchmark result
        run: git stash
        uses: benchmark-action/github-action-benchmark@v1
        with:
          name: Python Benchmark
          tool: 'pytest'
          output-file-path: benchmarks/output.json
          fail-on-alert: true
          github-token: ${{ secrets.GITHUB_TOKEN }}
          auto-push: true
          comment-on-alert: true
          alert-threshold: '150%'
